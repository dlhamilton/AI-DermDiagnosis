{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "0aStgWSO0E0E"
      },
      "source": [
        "# **Modelling and Evaluation V5**"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "1eLEkw5O0ECa"
      },
      "source": [
        "## Objectives\n",
        "\n",
        "* Answer business requirement 1:\n",
        "    * The client aims to visually differentiate lesions. The model should be capable of reaching an accuracy of at least 70%.\n",
        "<br><br>\n",
        "\n",
        "* Answer business requirement 2:\n",
        "    - The model should provide a confidence level for each prediction.\n",
        "<br><br>\n",
        "\n",
        "* Answer business requirement 3:\n",
        "    - If a skin lesion is predicted as malignant with high confidence, the system should recommend immediate medical consultation.\n",
        "<br><br>\n",
        "\n",
        "* Answer business requirement 5:\n",
        "    - The AI model's insights should assist healthcare professionals in making informed decisions about the treatment process.\n",
        "<br><br>\n",
        "\n",
        "* Answer business requirement 6:\n",
        "    - The model's performance will be evaluated using balanced performance metrics such as F1 Score.\n",
        "<br><br>\n",
        "## Inputs\n",
        "\n",
        "* inputs/skin_cancer_dataset/sorted_images/train\n",
        "* inputs/skin_cancer_dataset/sorted_images/test\n",
        "* inputs/skin_cancer_dataset/sorted_images/validation\n",
        "* image shape embeddings\n",
        "\n",
        "## Outputs\n",
        "\n",
        "* Images distribution plot in train, validation, and test set.\n",
        "* Image augmentation.\n",
        "* Class indices to change prediction inference in labels.\n",
        "* Machine learning model creation and training.\n",
        "Save model.\n",
        "* Learning curve plot for model performance.\n",
        "* Model evaluation on pickle file.\n",
        "* Prediction on the random image file.\n",
        "\n",
        "## Additional Comments\n",
        "\n",
        "* V5 - Xception architecture as its base with smaller image size\n",
        "<br><br>\n",
        "\n",
        "* This model can be used for image classification tasks where you have multiple classes. It leverages the power of a pre-trained Xception model and fine-tunes it with additional custom layers to suit the specific classification problem."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "9uWZXH9LwoQg"
      },
      "source": [
        "---"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Import regular packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from matplotlib.image import imread\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "import joblib"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Change working directory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "current_dir = os.getcwd()\n",
        "current_dir"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "os.chdir(os.path.dirname(current_dir))\n",
        "print(\"You set a new current directory\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "current_dir = os.getcwd()\n",
        "current_dir"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Set input directories"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "9MWW8E7lz3i7"
      },
      "source": [
        "Set train, validation and test paths."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TwHsQRWjz3i9",
        "outputId": "86849db3-cd2f-4cc5-ebb8-2d0caafa1a2c"
      },
      "outputs": [],
      "source": [
        "my_data_dir = 'inputs/skin_cancer_dataset/sorted_images'\n",
        "train_path = my_data_dir + '/train'\n",
        "val_path = my_data_dir + '/validation'\n",
        "test_path = my_data_dir + '/test'"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Set output directory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "version = 'modelling_evaluation_v5'\n",
        "file_path = f'outputs/{version}'\n",
        "\n",
        "if 'outputs' in os.listdir(current_dir) and version in os.listdir(current_dir + '/outputs'):\n",
        "    print('Old version is already available create a new version.')\n",
        "    pass\n",
        "else:\n",
        "    os.makedirs(name=file_path)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Set label names"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "train_labels = os.listdir(train_path)\n",
        "print('Label for train set the images are', train_labels, 'there are', len(train_labels) )\n",
        "test_labels = os.listdir(test_path)\n",
        "print('Label for test set the images are', test_labels, 'there are', len(test_labels) )\n",
        "val_labels = os.listdir(val_path)\n",
        "print('Label for val set the images are', val_labels, 'there are', len(val_labels) )"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Set image shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "image_shape = (75, 75, 3)\n",
        "image_shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "joblib.dump(value=image_shape ,\n",
        "            filename=f\"{file_path}/image_shape.pkl\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import joblib\n",
        "image_shape = joblib.load(filename=f\"{file_path}/image_shape.pkl\")\n",
        "image_shape"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "ZY3l0-AxO93d"
      },
      "source": [
        "---"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Build training, validation and test set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "img_height = 75\n",
        "img_width = 75\n",
        "batch_size = 32\n",
        "\n",
        "my_seed = 123\n",
        "np.random.seed(my_seed)\n",
        "tf.random.set_seed(my_seed)\n",
        "\n",
        "df_train = tf.keras.utils.image_dataset_from_directory(\n",
        "    train_path,\n",
        "    seed=my_seed,\n",
        "    color_mode=\"rgb\",\n",
        "    image_size=(img_height, img_width),\n",
        "    batch_size=batch_size,\n",
        "    label_mode=\"int\"\n",
        ")\n",
        "\n",
        "df_val = tf.keras.utils.image_dataset_from_directory(\n",
        "    val_path,\n",
        "    seed=my_seed,\n",
        "    color_mode=\"rgb\",\n",
        "    image_size=(img_height, img_width),\n",
        "    batch_size=batch_size,\n",
        "    label_mode=\"int\"\n",
        ")\n",
        "\n",
        "df_test = tf.keras.utils.image_dataset_from_directory(\n",
        "    test_path,\n",
        "    seed=my_seed,\n",
        "    color_mode=\"rgb\",\n",
        "    image_size=(img_height, img_width),\n",
        "    batch_size=batch_size,\n",
        "    label_mode=\"int\"\n",
        ")\n",
        "\n",
        "class_names = df_train.class_names\n",
        "\n",
        "normalization_layer = tf.keras.layers.Rescaling(scale=1./255, offset=0)\n",
        "\n",
        "df_train = df_train.map(lambda x, y: (normalization_layer(x), y))\n",
        "df_val = df_val.map(lambda x, y: (normalization_layer(x), y))\n",
        "df_test = df_test.map(lambda x, y: (normalization_layer(x), y))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "y = np.concatenate([y for x, y in df_train], axis=0)\n",
        "print(len(y))\n",
        "print(len(df_train))\n",
        "ranges = [0] * 7\n",
        "for class_id in np.unique(y, axis=0):\n",
        "    for cl in y:\n",
        "        if (class_id == cl):\n",
        "            ranges[class_id] += 1\n",
        "    \n",
        "print(ranges)\n",
        "print(sum(ranges))"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Model creation"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ML model"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Import model packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from tensorflow.keras.layers import Flatten, Dense, Dropout, BatchNormalization, Activation\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.applications import Xception\n",
        "import tensorflow as tf"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def create_tf_model(num_classes, input_shape=image_shape):\n",
        "    base_model = Xception(include_top=False, weights='imagenet', input_shape=input_shape)\n",
        "    for layer in base_model.layers:\n",
        "        layer.trainable = True\n",
        "    \n",
        "    model = Sequential()\n",
        "    \n",
        "    model.add(base_model)\n",
        "\n",
        "    model.add(Flatten())\n",
        "\n",
        "    model.add(Dense(128))\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Activation('relu'))\n",
        "\n",
        "    model.add(Dense(num_classes))\n",
        "\n",
        "    model.compile(loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "                  optimizer='adam',\n",
        "                  metrics=['accuracy'])\n",
        "\n",
        "    return model"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Model Summary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "create_tf_model(num_classes=7).summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model = create_tf_model(num_classes=7)\n",
        "\n",
        "model.fit(df_train,\n",
        "          epochs=30,\n",
        "          validation_data=df_val,\n",
        "          )"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Save model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model.save(f'{file_path}/lesion_classifier_model.h5')"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Model Performance"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Model learning curve"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "losses = pd.DataFrame(model.history.history)\n",
        "\n",
        "sns.set_style(\"whitegrid\")\n",
        "losses[['loss', 'val_loss']].plot(style='.-')\n",
        "plt.title(\"Loss\")\n",
        "plt.savefig(f'{file_path}/model_training_losses.png',\n",
        "            bbox_inches='tight', dpi=150)\n",
        "plt.show()\n",
        "\n",
        "print(\"\\n\")\n",
        "losses[['accuracy', 'val_accuracy']].plot(style='.-')\n",
        "plt.title(\"Accuracy\")\n",
        "plt.savefig(f'{file_path}/model_training_acc.png',\n",
        "            bbox_inches='tight', dpi=150)\n",
        "plt.show()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Model Evaluation"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Load Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from keras.models import load_model\n",
        "model = load_model(f\"{file_path}/lesion_classifier_model.h5\")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Evaluate Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "evaluation = model.evaluate(df_test)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Save evaluation pickle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "joblib.dump(value=evaluation,\n",
        "            filename=f\"{file_path}/evaluation.pkl\")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Predict on new data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import random\n",
        "from tensorflow.keras.preprocessing import image\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.special import softmax\n",
        "\n",
        "target_map = {v: k for v, k in enumerate(class_names)}\n",
        "\n",
        "f, ax = plt.subplots(7, 5)  \n",
        "f.set_size_inches(20, 20) \n",
        "\n",
        "correct_counts = {label: 0 for label in class_names}\n",
        "total_counts = {label: 0 for label in class_names}\n",
        "\n",
        "for row, label in enumerate(class_names):\n",
        "    image_files = os.listdir(test_path + '/' + label)\n",
        "\n",
        "    random_indices = random.sample(range(len(image_files)), 5)\n",
        "\n",
        "    for col, idx in enumerate(random_indices):\n",
        "        pil_image = image.load_img(test_path + '/' + label + '/' + image_files[idx], target_size=image_shape, color_mode='rgb')\n",
        "        \n",
        "        my_image = image.img_to_array(pil_image)\n",
        "        my_image = np.expand_dims(my_image, axis=0)/255\n",
        "        \n",
        "        pred_logits = model.predict(my_image)[0]\n",
        "        pred_proba = softmax(pred_logits)\n",
        "        \n",
        "        pred_class_index = np.argmax(pred_proba)\n",
        "        pred_class = target_map[pred_class_index]\n",
        "        \n",
        "        probabilities_text = '\\n'.join([f\"{target_map[i]}: {p:.2f}\" for i, p in enumerate(pred_proba)])\n",
        "\n",
        "        is_correct = pred_class == label\n",
        "        if is_correct:\n",
        "            correct_counts[label] += 1\n",
        "        total_counts[label] += 1\n",
        "        \n",
        "        is_correct = 'Correct' if pred_class == label else 'Incorrect'\n",
        "        \n",
        "        ax[row, col].imshow(pil_image)\n",
        "        ax[row, col].set_title(f\"pred: {pred_class}\\nactual: {label}\\n{is_correct}\\n{probabilities_text}\")\n",
        "        \n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Predict on new data summary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "total_correct = 0\n",
        "for label in train_labels:\n",
        "    total_correct = total_correct + correct_counts[label] \n",
        "    accuracy = (correct_counts[label] / total_counts[label]) * 100 if total_counts[label] > 0 else 0\n",
        "    print(f\"Accuracy for class {label}: {accuracy:.2f}% ({correct_counts[label]}/{total_counts[label]})\")\n",
        "    \n",
        "total_accuracy = (total_correct / 35) * 100 if total_correct > 0 else 0\n",
        "print()\n",
        "print(f\"Total correct: {total_correct}\")\n",
        "print(f\"Accuracy total: {total_accuracy:.2f}% ({total_correct}/35)\")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Predict on new data single"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import random\n",
        "from tensorflow.keras.preprocessing import image\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.special import softmax\n",
        "\n",
        "from tensorflow.keras.preprocessing import image\n",
        "\n",
        "pointer = 2\n",
        "label = train_labels[1]  # select\n",
        "\n",
        "pil_image = image.load_img(test_path + '/' + label + '/'  + os.listdir(test_path+'/' + label)[pointer], target_size=image_shape, color_mode='rgb')\n",
        "print(f'Image shape: {pil_image.size}, Image mode: {pil_image.mode}')\n",
        "print(f'{label}')\n",
        "pil_image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "my_image = image.img_to_array(pil_image)\n",
        "my_image = np.expand_dims(my_image, axis=0)/255\n",
        "print(my_image.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "my_image = image.img_to_array(pil_image)\n",
        "my_image = np.expand_dims(my_image, axis=0)/255\n",
        "\n",
        "pred_logits = model.predict(my_image)[0]\n",
        "pred_proba = softmax(pred_logits)\n",
        "\n",
        "pred_class_index = np.argmax(pred_proba)\n",
        "pred_proba_max = np.max(pred_proba) \n",
        "\n",
        "target_map = {v: k for v, k in enumerate(class_names)}\n",
        "\n",
        "pred_class = target_map[pred_class_index]\n",
        "\n",
        "print(f\"Predicted Class: {pred_class}\")\n",
        "print(f\"Probability: {pred_proba_max:.2f}\")\n",
        "\n",
        "for i, prob in enumerate(pred_proba):\n",
        "    print(f\"Probability of {target_map[i]}: {prob:.2f}\")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Classification report "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "all_features = []\n",
        "all_labels = []\n",
        "\n",
        "for features, labels in df_test:\n",
        "    all_features.append(features.numpy())\n",
        "    all_labels.append(labels.numpy())\n",
        "\n",
        "all_features = np.concatenate(all_features, axis=0)\n",
        "all_labels = np.concatenate(all_labels, axis=0)\n",
        "\n",
        "print(\"Features shape:\", all_features.shape)\n",
        "print(\"Labels shape:\", all_labels.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "\n",
        "X_train = all_features\n",
        "y_true = all_labels\n",
        "\n",
        "y_pred = model.predict(X_train)\n",
        "\n",
        "y_pred_labels = np.argmax(y_pred, axis=1)\n",
        "\n",
        "unique_labels = np.unique(np.concatenate((y_true, y_pred_labels)))\n",
        "\n",
        "unique_class_names = [class_names[label] for label in unique_labels]\n",
        "\n",
        "cm = confusion_matrix(y_true, y_pred_labels, labels=unique_labels)\n",
        "\n",
        "plt.figure(figsize=(10,7))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=unique_class_names, yticklabels=unique_class_names)\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('True')\n",
        "plt.savefig(f'{file_path}/confusion_matrix.png')\n",
        "plt.show()\n",
        "\n",
        "class_report = classification_report(y_true, y_pred_labels, target_names=unique_class_names)\n",
        "\n",
        "with open(os.path.join(f'{file_path}/classification_report.txt'), 'w') as file:\n",
        "    file.write(class_report)\n",
        "\n",
        "print(class_report)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## AUC-ROC and precision-recall curve"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics import roc_curve, auc, precision_recall_curve, average_precision_score\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.preprocessing import label_binarize\n",
        "from tensorflow.keras.models import load_model\n",
        "import os\n",
        "\n",
        "model = load_model(f'{file_path}/lesion_classifier_model.h5')\n",
        "\n",
        "predictions = model.predict(df_val.map(lambda x, y: x))\n",
        "\n",
        "y_true = np.concatenate([y for _, y in df_val], axis=0)\n",
        "\n",
        "y_true_binarized = label_binarize(y_true, classes=range(len(class_names)))\n",
        "\n",
        "fpr = dict()\n",
        "tpr = dict()\n",
        "roc_auc = dict()\n",
        "\n",
        "n_classes = len(class_names)\n",
        "\n",
        "for i in range(n_classes):\n",
        "    fpr[i], tpr[i], _ = roc_curve(y_true_binarized[:, i], predictions[:, i])\n",
        "    roc_auc[i] = auc(fpr[i], tpr[i])\n",
        "\n",
        "plt.figure()\n",
        "for i, class_name in enumerate(class_names):\n",
        "    plt.plot(fpr[i], tpr[i], label=f'ROC curve of {class_name} (area = {roc_auc[i]:.2f})')\n",
        "plt.plot([0, 1], [0, 1], 'k--')\n",
        "plt.xlim([0.0, 1.0])\n",
        "plt.ylim([0.0, 1.05])\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('Receiver Operating Characteristic (ROC)')\n",
        "plt.legend(loc=\"lower right\")\n",
        "plt.savefig(f'{file_path}/roc_curves.png')\n",
        "plt.show()\n",
        "\n",
        "precision = dict()\n",
        "recall = dict()\n",
        "average_precision = dict()\n",
        "\n",
        "for i in range(n_classes):\n",
        "    precision[i], recall[i], _ = precision_recall_curve(y_true_binarized[:, i], predictions[:, i])\n",
        "    average_precision[i] = average_precision_score(y_true_binarized[:, i], predictions[:, i])\n",
        "\n",
        "plt.figure()\n",
        "for i, class_name in enumerate(class_names):\n",
        "    plt.plot(recall[i], precision[i], label=f'Precision-Recall curve of {class_name} (area = {average_precision[i]:.2f})')\n",
        "plt.xlim([0.0, 1.0])\n",
        "plt.ylim([0.0, 1.05])\n",
        "plt.xlabel('Recall')\n",
        "plt.ylabel('Precision')\n",
        "plt.title('Precision-Recall Curve')\n",
        "plt.legend(loc=\"lower right\")\n",
        "plt.savefig(f'{file_path}/precision_recall_curves.png')\n",
        "plt.show()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "NOTE"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The overall accuracy of the model on the test set is 81%. This means that the model correctly predicted the skin condition 81% of the time.\n",
        "\n",
        "When looking at individual classes, the model performed the best in identifying Melanocytic Nevi (nv) with a precision of 0.90 and recall of 0.92. Precision is the proportion of true positive identifications (i.e., the model correctly identified the condition) among all positive identifications, and recall is the proportion of true positive identifications among all actual positives.\n",
        "\n",
        "The model also performed reasonably well in identifying Vascular Lesions (vasc) with a precision of 0.73 and a recall of 0.83. For Dermatofibroma (df), the precision is 0.57 and recall is 0.71.\n",
        "\n",
        "However, the model had a relatively lower performance in identifying Actinic Keratosis (akiec) and Melanoma (mel). For akiec, the precision is 0.67 and the recall is 0.36, while for mel, the precision is 0.65 and the recall is 0.43.\n",
        "\n",
        "In general, the model showed good potential in diagnosing skin conditions but further improvements, especially for Actinic Keratosis and Melanoma classes, could enhance its diagnostic capability."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Data Practitioner Jupyter Notebook.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "interpreter": {
      "hash": "8b8334dab9339717f727a1deaf837b322d7a41c20d15cc86be99a8e69ceec8ce"
    },
    "kernelspec": {
      "display_name": "Python 3.8.12 64-bit ('3.8.12': pyenv)",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.12"
    },
    "orig_nbformat": 2
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
